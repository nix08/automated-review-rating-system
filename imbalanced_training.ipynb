{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b785f8b",
   "metadata": {},
   "source": [
    "# Imbalanced Review Dataset Preparation\n",
    "The following steps preprocess and lemmatize the imbalanced data. No balancing is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e2a2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.utils import resample\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Column names\n",
    "REVIEW_COL = \"Text\"\n",
    "LABEL_COL = \"Score\"\n",
    "\n",
    "IMBALANCED_PATH = r\"D:\\Projects\\automated-review-rating-system\\data\\cleaned_dataset\\imbalanced_data.csv\"\n",
    "IMBALANCED_SAVE_PATH = r\"D:\\Projects\\automated-review-rating-system\\data\\cleaned_dataset\\imbalanced_data_lemmatized.csv\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff4d57",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Remove unwanted characters, lowercase all text, and ensure no missing values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97b4d910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>review_length</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249591</td>\n",
       "      <td>B001LGGH54</td>\n",
       "      <td>AORGKBNQZ83O8</td>\n",
       "      <td>MacGuffin \"MacGuffin\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1235865600</td>\n",
       "      <td>Interesting</td>\n",
       "      <td>i m always down to review a beverage if it mee...</td>\n",
       "      <td>1709</td>\n",
       "      <td>i m always down to review a beverage if it mee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>542900</td>\n",
       "      <td>B0001HAEJY</td>\n",
       "      <td>A289SYWE4BHCF</td>\n",
       "      <td>akilah</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1351209600</td>\n",
       "      <td>Great!</td>\n",
       "      <td>very good product great for your blood you wil...</td>\n",
       "      <td>196</td>\n",
       "      <td>very good product great for your blood you wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>310716</td>\n",
       "      <td>B002QZ7ZBY</td>\n",
       "      <td>A8JB6RLAKR0T0</td>\n",
       "      <td>Mary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1340668800</td>\n",
       "      <td>Delicious chips but wrong order!</td>\n",
       "      <td>i love pita chips and i love stacy s unfortuna...</td>\n",
       "      <td>631</td>\n",
       "      <td>i love pita chip and i love stacy s unfortunat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372491</td>\n",
       "      <td>B0083T6HC0</td>\n",
       "      <td>A2QCHBEXUBN2S8</td>\n",
       "      <td>Alaskan \"Alaskan\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1346716800</td>\n",
       "      <td>K-Cups</td>\n",
       "      <td>i love the assorted k cups it is a great way t...</td>\n",
       "      <td>151</td>\n",
       "      <td>i love the assorted k cup it is a great way to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>164438</td>\n",
       "      <td>B0000E2T62</td>\n",
       "      <td>AZ1ZE53AR3EWO</td>\n",
       "      <td>Jane916</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1323216000</td>\n",
       "      <td>Gumballs</td>\n",
       "      <td>the ad for gumballs on amazon indicated they w...</td>\n",
       "      <td>137</td>\n",
       "      <td>the ad for gumballs on amazon indicated they w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id   ProductId          UserId            ProfileName  \\\n",
       "0  249591  B001LGGH54   AORGKBNQZ83O8  MacGuffin \"MacGuffin\"   \n",
       "1  542900  B0001HAEJY   A289SYWE4BHCF                 akilah   \n",
       "2  310716  B002QZ7ZBY   A8JB6RLAKR0T0                   Mary   \n",
       "3  372491  B0083T6HC0  A2QCHBEXUBN2S8      Alaskan \"Alaskan\"   \n",
       "4  164438  B0000E2T62   AZ1ZE53AR3EWO                Jane916   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     0                       0      4  1235865600   \n",
       "1                     0                       0      5  1351209600   \n",
       "2                     0                       0      3  1340668800   \n",
       "3                     0                       0      5  1346716800   \n",
       "4                     0                       0      1  1323216000   \n",
       "\n",
       "                            Summary  \\\n",
       "0                       Interesting   \n",
       "1                            Great!   \n",
       "2  Delicious chips but wrong order!   \n",
       "3                            K-Cups   \n",
       "4                          Gumballs   \n",
       "\n",
       "                                                Text  review_length  \\\n",
       "0  i m always down to review a beverage if it mee...           1709   \n",
       "1  very good product great for your blood you wil...            196   \n",
       "2  i love pita chips and i love stacy s unfortuna...            631   \n",
       "3  i love the assorted k cups it is a great way t...            151   \n",
       "4  the ad for gumballs on amazon indicated they w...            137   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  i m always down to review a beverage if it mee...  \n",
       "1  very good product great for your blood you wil...  \n",
       "2  i love pita chip and i love stacy s unfortunat...  \n",
       "3  i love the assorted k cup it is a great way to...  \n",
       "4  the ad for gumballs on amazon indicated they w...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = ''.join(char if char.isalpha() or char.isspace() else ' ' for char in text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "df_imbalanced[REVIEW_COL] = df_imbalanced[REVIEW_COL].apply(clean_text)\n",
    "df_imbalanced = df_imbalanced.dropna(subset=[REVIEW_COL, LABEL_COL]).reset_index(drop=True)\n",
    "df_imbalanced.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f514042",
   "metadata": {},
   "source": [
    "## Text Lemmatization\n",
    "Lemmatize every review so words are reduced to their root forms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dfe3031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>review_length</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249591</td>\n",
       "      <td>B001LGGH54</td>\n",
       "      <td>AORGKBNQZ83O8</td>\n",
       "      <td>MacGuffin \"MacGuffin\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1235865600</td>\n",
       "      <td>Interesting</td>\n",
       "      <td>i m always down to review a beverage if it mee...</td>\n",
       "      <td>1709</td>\n",
       "      <td>i m always down to review a beverage if it mee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>542900</td>\n",
       "      <td>B0001HAEJY</td>\n",
       "      <td>A289SYWE4BHCF</td>\n",
       "      <td>akilah</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1351209600</td>\n",
       "      <td>Great!</td>\n",
       "      <td>very good product great for your blood you wil...</td>\n",
       "      <td>196</td>\n",
       "      <td>very good product great for your blood you wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>310716</td>\n",
       "      <td>B002QZ7ZBY</td>\n",
       "      <td>A8JB6RLAKR0T0</td>\n",
       "      <td>Mary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1340668800</td>\n",
       "      <td>Delicious chips but wrong order!</td>\n",
       "      <td>i love pita chips and i love stacy s unfortuna...</td>\n",
       "      <td>631</td>\n",
       "      <td>i love pita chip and i love stacy s unfortunat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372491</td>\n",
       "      <td>B0083T6HC0</td>\n",
       "      <td>A2QCHBEXUBN2S8</td>\n",
       "      <td>Alaskan \"Alaskan\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1346716800</td>\n",
       "      <td>K-Cups</td>\n",
       "      <td>i love the assorted k cups it is a great way t...</td>\n",
       "      <td>151</td>\n",
       "      <td>i love the assorted k cup it is a great way to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>164438</td>\n",
       "      <td>B0000E2T62</td>\n",
       "      <td>AZ1ZE53AR3EWO</td>\n",
       "      <td>Jane916</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1323216000</td>\n",
       "      <td>Gumballs</td>\n",
       "      <td>the ad for gumballs on amazon indicated they w...</td>\n",
       "      <td>137</td>\n",
       "      <td>the ad for gumballs on amazon indicated they w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id   ProductId          UserId            ProfileName  \\\n",
       "0  249591  B001LGGH54   AORGKBNQZ83O8  MacGuffin \"MacGuffin\"   \n",
       "1  542900  B0001HAEJY   A289SYWE4BHCF                 akilah   \n",
       "2  310716  B002QZ7ZBY   A8JB6RLAKR0T0                   Mary   \n",
       "3  372491  B0083T6HC0  A2QCHBEXUBN2S8      Alaskan \"Alaskan\"   \n",
       "4  164438  B0000E2T62   AZ1ZE53AR3EWO                Jane916   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     0                       0      4  1235865600   \n",
       "1                     0                       0      5  1351209600   \n",
       "2                     0                       0      3  1340668800   \n",
       "3                     0                       0      5  1346716800   \n",
       "4                     0                       0      1  1323216000   \n",
       "\n",
       "                            Summary  \\\n",
       "0                       Interesting   \n",
       "1                            Great!   \n",
       "2  Delicious chips but wrong order!   \n",
       "3                            K-Cups   \n",
       "4                          Gumballs   \n",
       "\n",
       "                                                Text  review_length  \\\n",
       "0  i m always down to review a beverage if it mee...           1709   \n",
       "1  very good product great for your blood you wil...            196   \n",
       "2  i love pita chips and i love stacy s unfortuna...            631   \n",
       "3  i love the assorted k cups it is a great way t...            151   \n",
       "4  the ad for gumballs on amazon indicated they w...            137   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  i m always down to review a beverage if it mee...  \n",
       "1  very good product great for your blood you wil...  \n",
       "2  i love pita chip and i love stacy s unfortunat...  \n",
       "3  i love the assorted k cup it is a great way to...  \n",
       "4  the ad for gumballs on amazon indicated they w...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized)\n",
    "\n",
    "df_imbalanced[\"lemmatized_text\"] = df_imbalanced[REVIEW_COL].apply(lemmatize_text)\n",
    "df_imbalanced.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e7020e",
   "metadata": {},
   "source": [
    "## Save Processed Imbalanced Dataset\n",
    "Save the cleaned and lemmatized imbalanced dataset for use in model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6e70c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalanced dataset saved to: D:\\Projects\\automated-review-rating-system\\data\\cleaned_dataset\\imbalanced_data_lemmatized.csv\n"
     ]
    }
   ],
   "source": [
    "save_columns = [REVIEW_COL, \"lemmatized_text\", LABEL_COL]\n",
    "df_imbalanced.to_csv(IMBALANCED_SAVE_PATH, index=False, columns=save_columns)\n",
    "print(f\"Imbalanced dataset saved to: {IMBALANCED_SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8357674f",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "Using TF-IDF vectorization on the lemmatized text column to convert reviews into numerical features for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45dcbdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEW_COL = \"Text\"\n",
    "LEMMATIZED_COL = \"lemmatized_text\"\n",
    "LABEL_COL = \"Score\"\n",
    "\n",
    "# Load your data\n",
    "df_imbalanced = pd.read_csv('data\\cleaned_dataset\\imbalanced_data_lemmatized.csv')\n",
    "\n",
    "# Now you can safely use\n",
    "X = df_imbalanced[LEMMATIZED_COL]\n",
    "y = df_imbalanced[LABEL_COL]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4068ea",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "Split data into training and test sets for unbiased evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b682f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_vec = tfidf.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc0c7b9",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "Train a Logistic Regression model on the imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b37c16b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.375\n",
      "Confusion Matrix:\n",
      " [[17  8  8  4  3]\n",
      " [23 13  9  7  8]\n",
      " [ 8 23 36 22 11]\n",
      " [ 7 12 29 43 29]\n",
      " [ 7  7  6 19 41]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.27      0.42      0.33        40\n",
      "           2       0.21      0.22      0.21        60\n",
      "           3       0.41      0.36      0.38       100\n",
      "           4       0.45      0.36      0.40       120\n",
      "           5       0.45      0.51      0.48        80\n",
      "\n",
      "    accuracy                           0.38       400\n",
      "   macro avg       0.36      0.37      0.36       400\n",
      "weighted avg       0.39      0.38      0.38       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Use class_weight='balanced'\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33eb03e",
   "metadata": {},
   "source": [
    "GridSearchCV for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7296eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters: {'C': 1, 'class_weight': 'balanced', 'max_iter': 500, 'solver': 'liblinear'}\n",
      "Best cross-validation accuracy: 0.4381\n",
      "Tuned Model Accuracy: 0.405\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.38      0.36        40\n",
      "           2       0.23      0.20      0.21        60\n",
      "           3       0.41      0.41      0.41       100\n",
      "           4       0.45      0.42      0.43       120\n",
      "           5       0.46      0.55      0.50        80\n",
      "\n",
      "    accuracy                           0.41       400\n",
      "   macro avg       0.38      0.39      0.38       400\n",
      "weighted avg       0.40      0.41      0.40       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"],\n",
    "    \"max_iter\": [500, 1000],\n",
    "    \"class_weight\": [\"balanced\"]  # Ensure imbalance handling\n",
    "}\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "grid = GridSearchCV(lr, param_grid, scoring=\"accuracy\", cv=5, n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate the best model\n",
    "best_lr = grid.best_estimator_\n",
    "y_pred_best = best_lr.predict(X_test)\n",
    "print(\"Tuned Model Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5db27b",
   "metadata": {},
   "source": [
    "Fetch best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de2eff66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Model Accuracy: 0.405\n",
      "\n",
      "Confusion Matrix:\n",
      " [[15  8 10  5  2]\n",
      " [17 12 14  7 10]\n",
      " [ 4 19 41 26 10]\n",
      " [ 5  8 28 50 29]\n",
      " [ 2  6  6 22 44]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.38      0.36        40\n",
      "           2       0.23      0.20      0.21        60\n",
      "           3       0.41      0.41      0.41       100\n",
      "           4       0.45      0.42      0.43       120\n",
      "           5       0.46      0.55      0.50        80\n",
      "\n",
      "    accuracy                           0.41       400\n",
      "   macro avg       0.38      0.39      0.38       400\n",
      "weighted avg       0.40      0.41      0.40       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "best_lr = grid.best_estimator_\n",
    "y_pred_best = best_lr.predict(X_test)\n",
    "\n",
    "print(\"Tuned Model Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bb64ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and vectorizer saved as model_B_imbalanced.pkl and vectorizer_model_B.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best Logistic Regression model after tuning\n",
    "joblib.dump(best_lr, \"model_B_imbalanced.pkl\")\n",
    "\n",
    "# Save the TF-IDF vectorizer (make sure to use the one used for train/test split)\n",
    "joblib.dump(tfidf, \"vectorizer_model_B.pkl\")\n",
    "\n",
    "print(\"Model and vectorizer saved as model_B_imbalanced.pkl and vectorizer_model_B.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0ec68f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
