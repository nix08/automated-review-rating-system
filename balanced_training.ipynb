{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fafc561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Id   ProductId          UserId                ProfileName  \\\n",
      "0  171065  B00009ZIY2  A362H8YI6T7B2I       Patricia J Gilchrist   \n",
      "1    9366  B006N3IG4K  A1KJDUS91L5OOE                 bears22687   \n",
      "2  410515  B000FIXYDC  A2C8O554YMY2ZL              Bixby \"Bixby\"   \n",
      "3  482561  B000G2UUDO  A145B9FRIAAHAY  Rita's talented tastebuds   \n",
      "4  120766  B005K4Q37A  A1UQFVHBQJ2K8Z                     Brenda   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     0                       0      1  1322438400   \n",
      "1                     0                       1      1  1343952000   \n",
      "2                     1                       2      1  1315785600   \n",
      "3                     3                       6      1  1278288000   \n",
      "4                     2                       5      1  1325808000   \n",
      "\n",
      "                     Summary  \\\n",
      "0      not what we wanted...   \n",
      "1                   not good   \n",
      "2  Strange taste and texture   \n",
      "3          AWFUL!!! AWFUL!!!   \n",
      "4    Grove Square Cappuchino   \n",
      "\n",
      "                                                Text  review_length  \n",
      "0  We have two very picky cats who loved the old ...            343  \n",
      "1  The coffee tasted bitter and like it was burnt...            136  \n",
      "2  I purchased a can that the store before I boug...            343  \n",
      "3  This product is a perfect example for the erro...           1096  \n",
      "4  I found that Grove Square French Vanilla Cappu...            430  \n",
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text',\n",
      "       'review_length'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read your cleaned, balanced dataset\n",
    "bal_path = r'D:\\Projects\\automated-review-rating-system\\data\\cleaned_dataset\\balanced_data.csv'\n",
    "df_bal = pd.read_csv(bal_path)\n",
    "print(df_bal.head())\n",
    "print(df_bal.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d9ac752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text',\n",
      "       'review_length'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22074840",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal.drop(['Id', 'ProductId','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator','Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d258085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after dropping unnecessary ones:\n",
      "Index(['Score', 'Summary', 'Text', 'review_length'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_bal.to_csv('balanced_dataset.csv', index=False)\n",
    "print(\"Columns after dropping unnecessary ones:\")\n",
    "print(df_bal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81e20596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Score', 'Summary', 'Text', 'review_length'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11ba1b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Score', 'Summary', 'Text', 'review_length'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30a53749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal.to_csv('balanced_dataset_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "387988dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Score', 'Summary', 'Text', 'review_length'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e2cd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score            0\n",
      "Summary          1\n",
      "Text             0\n",
      "review_length    0\n",
      "dtype: int64\n",
      "No null values found in the dataset after cleaning.\n",
      "Score\n",
      "1    2000\n",
      "2    2000\n",
      "3    2000\n",
      "4    2000\n",
      "5    2000\n",
      "Name: count, dtype: int64\n",
      "Balanced dataset saved as 'balanced_dataset_cleaned.csv'.\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.isnull().sum())\n",
    "print(\"No null values found in the dataset after cleaning.\")\n",
    "print(df_bal['Score'].value_counts())\n",
    "print(\"Balanced dataset saved as 'balanced_dataset_cleaned.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41aaf69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    we have two very picky cat who love the old or...\n",
      "1    the coffee taste bitter and like it be burn I ...\n",
      "2    I purchase a can that the store before I buy a...\n",
      "3    this product be a perfect example for the erro...\n",
      "4    I find that Grove Square French Vanilla Cappuc...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return ' '.join([token.lemma_ for token in doc if not token.is_punct and not token.is_space])\n",
    "\n",
    "df_bal['Text'] = df_bal['Text'].apply(lemmatize_text)\n",
    "print(df_bal['Text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ddfbc",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b4d0852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  \\\n",
      "0  we have two very picky cat who love the old or...   \n",
      "1  the coffee taste bitter and like it be burn I ...   \n",
      "2  I purchase a can that the store before I buy a...   \n",
      "3  this product be a perfect example for the erro...   \n",
      "4  I find that Grove Square French Vanilla Cappuc...   \n",
      "\n",
      "                                          clean_text  \\\n",
      "0  we have two very picky cat who love the old or...   \n",
      "1  the coffee taste bitter and like it be burn i ...   \n",
      "2  i purchase a can that the store before i buy a...   \n",
      "3  this product be a perfect example for the erro...   \n",
      "4  i find that grove square french vanilla cappuc...   \n",
      "\n",
      "                                          lemmatized  \n",
      "0  picky cat love old original whiskas think phot...  \n",
      "1  coffee taste bitter like burn clean machine ta...  \n",
      "2  purchase store buy pack amazon try gross love ...  \n",
      "3  product perfect example erroneous notion label...  \n",
      "4  find grove square french vanilla cappuchino pl...  \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Lowercase, remove URLs, HTML tags, emojis, punctuation, non-ASCII, digits, extra whitespace.\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text) # Remove emojis/unicode\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)        # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)            # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\"\n",
    "    Lemmatize using spaCy, remove stopwords, keep alphabetic tokens longer than 1 character.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha and len(token.lemma_) > 1]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df_bal['clean_text'] = df_bal['Text'].apply(clean_text)\n",
    "df_bal['lemmatized'] = df_bal['clean_text'].apply(lemmatize_text)\n",
    "print(df_bal[['Text', 'clean_text', 'lemmatized']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fbbb99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Score', 'Summary', 'Text', 'review_length', 'clean_text',\n",
      "       'lemmatized'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9313a40c",
   "metadata": {},
   "source": [
    "Text Cleaning + Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00f14624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  \\\n",
      "0  we have two very picky cat who love the old or...   \n",
      "1  the coffee taste bitter and like it be burn I ...   \n",
      "2  I purchase a can that the store before I buy a...   \n",
      "3  this product be a perfect example for the erro...   \n",
      "4  I find that Grove Square French Vanilla Cappuc...   \n",
      "\n",
      "                                          clean_text  \\\n",
      "0  we have two very picky cat who love the old or...   \n",
      "1  the coffee taste bitter and like it be burn i ...   \n",
      "2  i purchase a can that the store before i buy a...   \n",
      "3  this product be a perfect example for the erro...   \n",
      "4  i find that grove square french vanilla cappuc...   \n",
      "\n",
      "                                          lemmatized  \n",
      "0  picky cat love old original whiskas think phot...  \n",
      "1  coffee taste bitter like burn clean machine ta...  \n",
      "2  purchase store buy pack amazon try gross love ...  \n",
      "3  product perfect example erroneous notion label...  \n",
      "4  find grove square french vanilla cappuchino pl...  \n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Lowercase, remove URLs, HTML tags, emojis, punctuation, non-ASCII, digits, extra whitespace.\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text) # Remove emojis/unicode\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)        # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)            # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\"\n",
    "    Lemmatize using spaCy, remove stopwords, keep alphabetic tokens longer than 1 character.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha and len(token.lemma_) > 1]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# If not already, apply cleaning + lemmatization\n",
    "df_bal['clean_text'] = df_bal['Text'].apply(clean_text)\n",
    "df_bal['lemmatized'] = df_bal['clean_text'].apply(lemmatize_text)\n",
    "print(df_bal[['Text', 'clean_text', 'lemmatized']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46a4cd4",
   "metadata": {},
   "source": [
    " Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "239466fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution:\n",
      " Score\n",
      "1    1600\n",
      "4    1600\n",
      "3    1600\n",
      "2    1600\n",
      "5    1600\n",
      "Name: count, dtype: int64\n",
      "Test distribution:\n",
      " Score\n",
      "1    400\n",
      "2    400\n",
      "3    400\n",
      "5    400\n",
      "4    400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_bal['lemmatized']  # Using lemmatized column\n",
    "y = df_bal['Score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Train distribution:\\n\", y_train.value_counts())\n",
    "print(\"Test distribution:\\n\", y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4196c6e",
   "metadata": {},
   "source": [
    "TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e979a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF train shape: (8000, 18363)\n",
      "TF-IDF test shape: (2000, 18363)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_vec = tfidf.fit_transform(X_train)\n",
    "X_test_vec = tfidf.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF train shape:\", X_train_vec.shape)\n",
    "print(\"TF-IDF test shape:\", X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c45a95d",
   "metadata": {},
   "source": [
    "Model Training with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db1d833b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.461\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1      0.554     0.620     0.585       400\n",
      "           2      0.410     0.372     0.391       400\n",
      "           3      0.410     0.378     0.393       400\n",
      "           4      0.390     0.380     0.385       400\n",
      "           5      0.515     0.555     0.534       400\n",
      "\n",
      "    accuracy                          0.461      2000\n",
      "   macro avg      0.456     0.461     0.458      2000\n",
      "weighted avg      0.456     0.461     0.458      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[248  77  36  18  21]\n",
      " [103 149  75  45  28]\n",
      " [ 54  74 151  80  41]\n",
      " [ 18  35  76 152 119]\n",
      " [ 25  28  30  95 222]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  \n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=3))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a789172",
   "metadata": {},
   "source": [
    "Hyper Parameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49905075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "\n",
      "Best Hyperparameters: {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.62      0.58       400\n",
      "           2       0.41      0.35      0.38       400\n",
      "           3       0.42      0.36      0.39       400\n",
      "           4       0.38      0.36      0.37       400\n",
      "           5       0.51      0.59      0.55       400\n",
      "\n",
      "    accuracy                           0.46      2000\n",
      "   macro avg       0.45      0.46      0.45      2000\n",
      "weighted avg       0.45      0.46      0.45      2000\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[249  73  33  20  25]\n",
      " [109 142  74  44  31]\n",
      " [ 58  72 144  82  44]\n",
      " [ 20  35  70 144 131]\n",
      " [ 25  26  25  87 237]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "X = df_bal['lemmatized']\n",
    "y = df_bal['Score']\n",
    "\n",
    "# 1 Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "#  Convert text to numeric vectors using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Apply SMOTE only to numeric vectors (for balanced training)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "# Logistic Regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Hyperparameter search space\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],   # Regularization strength\n",
    "    'penalty': ['l1', 'l2'],        # Norm type\n",
    "    'solver': ['liblinear'],        # Solver that supports l1 and l2 penalties\n",
    "    'max_iter': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=logreg,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 7️⃣ Fit the best model on balanced data\n",
    "grid_search.fit(X_train_bal, y_train_bal)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predictions on test set (using original test vectorized data)\n",
    "y_pred = best_model.predict(X_test_vec)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c601dfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model A and its vectorizer have been saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best trained balanced model as Model A\n",
    "joblib.dump(best_model, 'model_A_balanced.pkl')\n",
    "\n",
    "# Save the TF-IDF vectorizer used for training\n",
    "joblib.dump(vectorizer, 'vectorizer_model_A.pkl')\n",
    "\n",
    "print(\"✅ Model A and its vectorizer have been saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab7d00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
