{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fafc561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Id   ProductId          UserId                ProfileName  \\\n",
      "0  171065  B00009ZIY2  A362H8YI6T7B2I       Patricia J Gilchrist   \n",
      "1    9366  B006N3IG4K  A1KJDUS91L5OOE                 bears22687   \n",
      "2  410515  B000FIXYDC  A2C8O554YMY2ZL              Bixby \"Bixby\"   \n",
      "3  482561  B000G2UUDO  A145B9FRIAAHAY  Rita's talented tastebuds   \n",
      "4  120766  B005K4Q37A  A1UQFVHBQJ2K8Z                     Brenda   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     0                       0      1  1322438400   \n",
      "1                     0                       1      1  1343952000   \n",
      "2                     1                       2      1  1315785600   \n",
      "3                     3                       6      1  1278288000   \n",
      "4                     2                       5      1  1325808000   \n",
      "\n",
      "                     Summary  \\\n",
      "0      not what we wanted...   \n",
      "1                   not good   \n",
      "2  Strange taste and texture   \n",
      "3          AWFUL!!! AWFUL!!!   \n",
      "4    Grove Square Cappuchino   \n",
      "\n",
      "                                                Text  review_length  \n",
      "0  We have two very picky cats who loved the old ...            343  \n",
      "1  The coffee tasted bitter and like it was burnt...            136  \n",
      "2  I purchased a can that the store before I boug...            343  \n",
      "3  This product is a perfect example for the erro...           1096  \n",
      "4  I found that Grove Square French Vanilla Cappu...            430  \n",
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text',\n",
      "       'review_length'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read your cleaned, balanced dataset\n",
    "bal_path = r'D:\\Projects\\automated-review-rating-system\\data\\cleaned_dataset\\balanced_data.csv'\n",
    "df_bal = pd.read_csv(bal_path)\n",
    "print(df_bal.head())\n",
    "print(df_bal.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d9ac752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text',\n",
      "       'review_length'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22074840",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal.drop(['Id', 'ProductId','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator','Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d258085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after dropping unnecessary ones:\n",
      "Index(['Score', 'Summary', 'Text', 'review_length'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_bal.to_csv('balanced_dataset.csv', index=False)\n",
    "print(\"Columns after dropping unnecessary ones:\")\n",
    "print(df_bal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81e20596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Score', 'Summary', 'Text', 'review_length'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11ba1b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Score', 'Summary', 'Text', 'review_length'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30a53749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal.to_csv('balanced_dataset_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "387988dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Score', 'Summary', 'Text', 'review_length'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1e2cd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score            0\n",
      "Summary          1\n",
      "Text             0\n",
      "review_length    0\n",
      "dtype: int64\n",
      "No null values found in the dataset after cleaning.\n",
      "Score\n",
      "1    2000\n",
      "2    2000\n",
      "3    2000\n",
      "4    2000\n",
      "5    2000\n",
      "Name: count, dtype: int64\n",
      "Balanced dataset saved as 'balanced_dataset_cleaned.csv'.\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.isnull().sum())\n",
    "print(\"No null values found in the dataset after cleaning.\")\n",
    "print(df_bal['Score'].value_counts())\n",
    "print(\"Balanced dataset saved as 'balanced_dataset_cleaned.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41aaf69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    we have two very picky cat who love the old or...\n",
      "1    the coffee taste bitter and like it be burn I ...\n",
      "2    I purchase a can that the store before I buy a...\n",
      "3    this product be a perfect example for the erro...\n",
      "4    I find that Grove Square French Vanilla Cappuc...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return ' '.join([token.lemma_ for token in doc if not token.is_punct and not token.is_space])\n",
    "\n",
    "df_bal['Text'] = df_bal['Text'].apply(lemmatize_text)\n",
    "print(df_bal['Text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ddfbc",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b4d0852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  \\\n",
      "0  we have two very picky cat who love the old or...   \n",
      "1  the coffee taste bitter and like it be burn I ...   \n",
      "2  I purchase a can that the store before I buy a...   \n",
      "3  this product be a perfect example for the erro...   \n",
      "4  I find that Grove Square French Vanilla Cappuc...   \n",
      "\n",
      "                                          clean_text  \\\n",
      "0  we have two very picky cat who love the old or...   \n",
      "1  the coffee taste bitter and like it be burn i ...   \n",
      "2  i purchase a can that the store before i buy a...   \n",
      "3  this product be a perfect example for the erro...   \n",
      "4  i find that grove square french vanilla cappuc...   \n",
      "\n",
      "                                          lemmatized  \n",
      "0  picky cat love old original whiskas think phot...  \n",
      "1  coffee taste bitter like burn clean machine ta...  \n",
      "2  purchase store buy pack amazon try gross love ...  \n",
      "3  product perfect example erroneous notion label...  \n",
      "4  find grove square french vanilla cappuchino pl...  \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Lowercase, remove URLs, HTML tags, emojis, punctuation, non-ASCII, digits, extra whitespace.\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text) # Remove emojis/unicode\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)        # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)            # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\"\n",
    "    Lemmatize using spaCy, remove stopwords, keep alphabetic tokens longer than 1 character.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha and len(token.lemma_) > 1]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df_bal['clean_text'] = df_bal['Text'].apply(clean_text)\n",
    "df_bal['lemmatized'] = df_bal['clean_text'].apply(lemmatize_text)\n",
    "print(df_bal[['Text', 'clean_text', 'lemmatized']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fbbb99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text',\n",
      "       'review_length', 'clean_text', 'lemmatized'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9313a40c",
   "metadata": {},
   "source": [
    "Text Cleaning + Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00f14624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  \\\n",
      "0  we have two very picky cat who love the old or...   \n",
      "1  the coffee taste bitter and like it be burn I ...   \n",
      "2  I purchase a can that the store before I buy a...   \n",
      "3  this product be a perfect example for the erro...   \n",
      "4  I find that Grove Square French Vanilla Cappuc...   \n",
      "\n",
      "                                          clean_text  \\\n",
      "0  we have two very picky cat who love the old or...   \n",
      "1  the coffee taste bitter and like it be burn i ...   \n",
      "2  i purchase a can that the store before i buy a...   \n",
      "3  this product be a perfect example for the erro...   \n",
      "4  i find that grove square french vanilla cappuc...   \n",
      "\n",
      "                                          lemmatized  \n",
      "0  picky cat love old original whiskas think phot...  \n",
      "1  coffee taste bitter like burn clean machine ta...  \n",
      "2  purchase store buy pack amazon try gross love ...  \n",
      "3  product perfect example erroneous notion label...  \n",
      "4  find grove square french vanilla cappuchino pl...  \n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Lowercase, remove URLs, HTML tags, emojis, punctuation, non-ASCII, digits, extra whitespace.\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text) # Remove emojis/unicode\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)        # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)            # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\"\n",
    "    Lemmatize using spaCy, remove stopwords, keep alphabetic tokens longer than 1 character.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha and len(token.lemma_) > 1]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# If not already, apply cleaning + lemmatization\n",
    "df_bal['clean_text'] = df_bal['Text'].apply(clean_text)\n",
    "df_bal['lemmatized'] = df_bal['clean_text'].apply(lemmatize_text)\n",
    "print(df_bal[['Text', 'clean_text', 'lemmatized']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46a4cd4",
   "metadata": {},
   "source": [
    " Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "239466fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution:\n",
      " Score\n",
      "1    1600\n",
      "4    1600\n",
      "3    1600\n",
      "2    1600\n",
      "5    1600\n",
      "Name: count, dtype: int64\n",
      "Test distribution:\n",
      " Score\n",
      "1    400\n",
      "2    400\n",
      "3    400\n",
      "5    400\n",
      "4    400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df_bal['lemmatized']  # Using lemmatized column\n",
    "y = df_bal['Score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Train distribution:\\n\", y_train.value_counts())\n",
    "print(\"Test distribution:\\n\", y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4196c6e",
   "metadata": {},
   "source": [
    "TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e979a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF train shape: (8000, 18363)\n",
      "TF-IDF test shape: (2000, 18363)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_vec = tfidf.fit_transform(X_train)\n",
    "X_test_vec = tfidf.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF train shape:\", X_train_vec.shape)\n",
    "print(\"TF-IDF test shape:\", X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c45a95d",
   "metadata": {},
   "source": [
    "Model Training with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db1d833b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.461\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1      0.554     0.620     0.585       400\n",
      "           2      0.410     0.372     0.391       400\n",
      "           3      0.410     0.378     0.393       400\n",
      "           4      0.390     0.380     0.385       400\n",
      "           5      0.515     0.555     0.534       400\n",
      "\n",
      "    accuracy                          0.461      2000\n",
      "   macro avg      0.456     0.461     0.458      2000\n",
      "weighted avg      0.456     0.461     0.458      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[248  77  36  18  21]\n",
      " [103 149  75  45  28]\n",
      " [ 54  74 151  80  41]\n",
      " [ 18  35  76 152 119]\n",
      " [ 25  28  30  95 222]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  \n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=3))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba40459b",
   "metadata": {},
   "source": [
    "Model Training with Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd76dc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- RandomForest -----\n",
      "Accuracy: 0.4775\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1      0.515     0.632     0.568       400\n",
      "           2      0.469     0.345     0.398       400\n",
      "           3      0.442     0.350     0.391       400\n",
      "           4      0.434     0.403     0.418       400\n",
      "           5      0.499     0.657     0.567       400\n",
      "\n",
      "    accuracy                          0.477      2000\n",
      "   macro avg      0.472     0.478     0.468      2000\n",
      "weighted avg      0.472     0.477     0.468      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[253  55  30  24  38]\n",
      " [106 138  65  42  49]\n",
      " [ 72  54 140  74  60]\n",
      " [ 36  29  57 161 117]\n",
      " [ 24  18  25  70 263]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\n----- {name} -----\")\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=3))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    results[name] = acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834081e8",
   "metadata": {},
   "source": [
    "Model Training with Linear SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dff11b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- LinearSVC -----\n",
      "Accuracy: 0.4385\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1      0.547     0.600     0.572       400\n",
      "           2      0.413     0.380     0.396       400\n",
      "           3      0.383     0.367     0.375       400\n",
      "           4      0.347     0.310     0.328       400\n",
      "           5      0.473     0.535     0.502       400\n",
      "\n",
      "    accuracy                          0.439      2000\n",
      "   macro avg      0.433     0.439     0.435      2000\n",
      "weighted avg      0.433     0.439     0.435      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[240  70  35  29  26]\n",
      " [ 88 152  83  43  34]\n",
      " [ 57  73 147  82  41]\n",
      " [ 22  40  77 124 137]\n",
      " [ 32  33  42  79 214]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "models = {\n",
    "    \"LinearSVC\": LinearSVC(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\n----- {name} -----\")\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=3))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    results[name] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408bbaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
