{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fafc561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Id   ProductId          UserId                ProfileName  \\\n",
      "0  171065  B00009ZIY2  A362H8YI6T7B2I       Patricia J Gilchrist   \n",
      "1    9366  B006N3IG4K  A1KJDUS91L5OOE                 bears22687   \n",
      "2  410515  B000FIXYDC  A2C8O554YMY2ZL              Bixby \"Bixby\"   \n",
      "3  482561  B000G2UUDO  A145B9FRIAAHAY  Rita's talented tastebuds   \n",
      "4  120766  B005K4Q37A  A1UQFVHBQJ2K8Z                     Brenda   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     0                       0      1  1322438400   \n",
      "1                     0                       1      1  1343952000   \n",
      "2                     1                       2      1  1315785600   \n",
      "3                     3                       6      1  1278288000   \n",
      "4                     2                       5      1  1325808000   \n",
      "\n",
      "                     Summary  \\\n",
      "0      not what we wanted...   \n",
      "1                   not good   \n",
      "2  Strange taste and texture   \n",
      "3          AWFUL!!! AWFUL!!!   \n",
      "4    Grove Square Cappuchino   \n",
      "\n",
      "                                                Text  review_length  \n",
      "0  We have two very picky cats who loved the old ...            343  \n",
      "1  The coffee tasted bitter and like it was burnt...            136  \n",
      "2  I purchased a can that the store before I boug...            343  \n",
      "3  This product is a perfect example for the erro...           1096  \n",
      "4  I found that Grove Square French Vanilla Cappu...            430  \n",
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text',\n",
      "       'review_length'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read your cleaned, balanced dataset\n",
    "bal_path = r'D:\\Projects\\automated-review-rating-system\\data\\cleaned_dataset\\balanced_data.csv'\n",
    "df_bal = pd.read_csv(bal_path)\n",
    "print(df_bal.head())\n",
    "print(df_bal.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d9ac752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text',\n",
      "       'review_length'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22074840",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal.drop(['Id', 'ProductId','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator','Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d258085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after dropping unnecessary ones:\n",
      "Index(['Score', 'Summary', 'Text', 'review_length'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_bal.to_csv('balanced_dataset.csv', index=False)\n",
    "print(\"Columns after dropping unnecessary ones:\")\n",
    "print(df_bal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81e20596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text',\n",
      "       'review_length'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab500811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal.drop(['Id', 'ProductId','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator','Time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11ba1b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Score', 'Summary', 'Text', 'review_length'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30a53749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bal.to_csv('balanced_dataset_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "387988dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Score', 'Summary', 'Text', 'review_length'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1e2cd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score            0\n",
      "Summary          1\n",
      "Text             0\n",
      "review_length    0\n",
      "dtype: int64\n",
      "No null values found in the dataset after cleaning.\n",
      "Score\n",
      "1    2000\n",
      "2    2000\n",
      "3    2000\n",
      "4    2000\n",
      "5    2000\n",
      "Name: count, dtype: int64\n",
      "Balanced dataset saved as 'balanced_dataset_cleaned.csv'.\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.isnull().sum())\n",
    "print(\"No null values found in the dataset after cleaning.\")\n",
    "print(df_bal['Score'].value_counts())\n",
    "print(\"Balanced dataset saved as 'balanced_dataset_cleaned.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41aaf69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    we have two very picky cat who love the old or...\n",
      "1    the coffee taste bitter and like it be burn I ...\n",
      "2    I purchase a can that the store before I buy a...\n",
      "3    this product be a perfect example for the erro...\n",
      "4    I find that Grove Square French Vanilla Cappuc...\n",
      "Name: Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return ' '.join([token.lemma_ for token in doc if not token.is_punct and not token.is_space])\n",
    "\n",
    "df_bal['Text'] = df_bal['Text'].apply(lemmatize_text)\n",
    "print(df_bal['Text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ddfbc",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4d0852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  \\\n",
      "0  We have two very picky cats who loved the old ...   \n",
      "1  The coffee tasted bitter and like it was burnt...   \n",
      "2  I purchased a can that the store before I boug...   \n",
      "3  This product is a perfect example for the erro...   \n",
      "4  I found that Grove Square French Vanilla Cappu...   \n",
      "\n",
      "                                          clean_text  \\\n",
      "0  we have two very picky cats who loved the old ...   \n",
      "1  the coffee tasted bitter and like it was burnt...   \n",
      "2  i purchased a can that the store before i boug...   \n",
      "3  this product is a perfect example for the erro...   \n",
      "4  i found that grove square french vanilla cappu...   \n",
      "\n",
      "                                          lemmatized  \n",
      "0  picky cat love old original whiskas think phot...  \n",
      "1  coffee taste bitter like burn clean machine ta...  \n",
      "2  purchase store buy pack amazon try gross love ...  \n",
      "3  product perfect example erroneous notion label...  \n",
      "4  find grove square french vanilla cappuchino pl...  \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Lowercase, remove URLs, HTML tags, emojis, punctuation, non-ASCII, digits, extra whitespace.\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text) # Remove emojis/unicode\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)        # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)            # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\"\n",
    "    Lemmatize using spaCy, remove stopwords, keep alphabetic tokens longer than 1 character.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha and len(token.lemma_) > 1]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df_bal['clean_text'] = df_bal['Text'].apply(clean_text)\n",
    "df_bal['lemmatized'] = df_bal['clean_text'].apply(lemmatize_text)\n",
    "print(df_bal[['Text', 'clean_text', 'lemmatized']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fbbb99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text',\n",
      "       'review_length', 'clean_text', 'lemmatized'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_bal.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9313a40c",
   "metadata": {},
   "source": [
    "Text Cleaning + Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f14624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  \\\n",
      "0  We have two very picky cats who loved the old ...   \n",
      "1  The coffee tasted bitter and like it was burnt...   \n",
      "2  I purchased a can that the store before I boug...   \n",
      "3  This product is a perfect example for the erro...   \n",
      "4  I found that Grove Square French Vanilla Cappu...   \n",
      "\n",
      "                                          clean_text  \\\n",
      "0  we have two very picky cats who loved the old ...   \n",
      "1  the coffee tasted bitter and like it was burnt...   \n",
      "2  i purchased a can that the store before i boug...   \n",
      "3  this product is a perfect example for the erro...   \n",
      "4  i found that grove square french vanilla cappu...   \n",
      "\n",
      "                                          lemmatized  \n",
      "0  picky cat love old original whiskas think phot...  \n",
      "1  coffee taste bitter like burn clean machine ta...  \n",
      "2  purchase store buy pack amazon try gross love ...  \n",
      "3  product perfect example erroneous notion label...  \n",
      "4  find grove square french vanilla cappuchino pl...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Lowercase, remove URLs, HTML tags, emojis, punctuation, non-ASCII, digits, extra whitespace.\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text) # Remove emojis/unicode\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)        # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)            # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \"\"\"\n",
    "    Lemmatize using spaCy, remove stopwords, keep alphabetic tokens longer than 1 character.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha and len(token.lemma_) > 1]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# If not already, apply cleaning + lemmatization\n",
    "df_bal['clean_text'] = df_bal['Text'].apply(clean_text)\n",
    "df_bal['lemmatized'] = df_bal['clean_text'].apply(lemmatize_text)\n",
    "print(df_bal[['Text', 'clean_text', 'lemmatized']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46a4cd4",
   "metadata": {},
   "source": [
    " Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239466fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution:\n",
      " Score\n",
      "1    1600\n",
      "4    1600\n",
      "3    1600\n",
      "2    1600\n",
      "5    1600\n",
      "Name: count, dtype: int64\n",
      "Test distribution:\n",
      " Score\n",
      "1    400\n",
      "2    400\n",
      "3    400\n",
      "5    400\n",
      "4    400\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df_bal['lemmatized']  # Using lemmatized column\n",
    "y = df_bal['Score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(\"Train distribution:\\n\", y_train.value_counts())\n",
    "print(\"Test distribution:\\n\", y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4196c6e",
   "metadata": {},
   "source": [
    "TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e979a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF train shape: (8000, 21702)\n",
      "TF-IDF test shape: (2000, 21702)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_vec = tfidf.fit_transform(X_train)\n",
    "X_test_vec = tfidf.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF train shape:\", X_train_vec.shape)\n",
    "print(\"TF-IDF test shape:\", X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c45a95d",
   "metadata": {},
   "source": [
    "Model Training with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db1d833b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.456\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1      0.557     0.610     0.582       400\n",
      "           2      0.399     0.378     0.388       400\n",
      "           3      0.416     0.372     0.393       400\n",
      "           4      0.374     0.355     0.364       400\n",
      "           5      0.507     0.565     0.534       400\n",
      "\n",
      "    accuracy                          0.456      2000\n",
      "   macro avg      0.451     0.456     0.452      2000\n",
      "weighted avg      0.451     0.456     0.452      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[244  81  35  20  20]\n",
      " [102 151  73  44  30]\n",
      " [ 49  78 149  81  43]\n",
      " [ 19  41  71 142 127]\n",
      " [ 24  27  30  93 226]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  \n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=3))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba40459b",
   "metadata": {},
   "source": [
    "Model Training with Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd76dc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- RandomForest -----\n",
      "Accuracy: 0.4630\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1      0.507     0.632     0.563       400\n",
      "           2      0.432     0.335     0.377       400\n",
      "           3      0.440     0.350     0.390       400\n",
      "           4      0.416     0.367     0.390       400\n",
      "           5      0.485     0.630     0.548       400\n",
      "\n",
      "    accuracy                          0.463      2000\n",
      "   macro avg      0.456     0.463     0.454      2000\n",
      "weighted avg      0.456     0.463     0.454      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[253  64  28  17  38]\n",
      " [107 134  74  41  44]\n",
      " [ 73  60 140  72  55]\n",
      " [ 35  37  50 147 131]\n",
      " [ 31  15  26  76 252]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\n----- {name} -----\")\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=3))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    results[name] = acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834081e8",
   "metadata": {},
   "source": [
    "Model Training with Linear SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dff11b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- LinearSVC -----\n",
      "Accuracy: 0.4405\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1      0.544     0.578     0.560       400\n",
      "           2      0.408     0.393     0.400       400\n",
      "           3      0.407     0.398     0.402       400\n",
      "           4      0.355     0.315     0.334       400\n",
      "           5      0.468     0.520     0.493       400\n",
      "\n",
      "    accuracy                          0.441      2000\n",
      "   macro avg      0.436     0.440     0.438      2000\n",
      "weighted avg      0.436     0.441     0.438      2000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[231  75  40  30  24]\n",
      " [ 88 157  76  45  34]\n",
      " [ 52  71 159  75  43]\n",
      " [ 23  40  76 126 135]\n",
      " [ 31  42  40  79 208]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "models = {\n",
    "    \"LinearSVC\": LinearSVC(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, clf in models.items():\n",
    "    print(f\"\\n----- {name} -----\")\n",
    "    clf.fit(X_train_vec, y_train)\n",
    "    y_pred = clf.predict(X_test_vec)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=3))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    results[name] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408bbaa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
